{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Neural Networks and Deep Learning</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\"> Predictive Analysis - Image Processing</h2>\n",
    "\n",
    "[source](https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify handwritten digits using the famous MNIST data\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/mnist.png)\n",
    "\n",
    "The goal in this task is to take an image of a handwritten single digit, and determine what that digit is.  \n",
    "\n",
    "The data for this competition were taken from the MNIST dataset. The MNIST (\"Modified National Institute of Standards and Technology\") dataset is a classic within the Machine Learning community that has been extensively studied.  More detail about the dataset, including Machine Learning algorithms that have been tried on it and their levels of success, can be found at http://yann.lecun.com/exdb/mnist/index.html.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import pylab\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "#matplotlib.rcdefaults()\n",
    "#matplotlib.verbose.set_level('silent')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 10:35:36.238686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 10:35:36.266496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 10:35:36.266640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "try:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU') \n",
    "    #tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "    print(physical_devices)\n",
    "except:\n",
    "    print(\"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.python.keras import utils\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# let's print the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the images from the 28x28 pixels to 1D 787 pixels\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 10:35:36.562369: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-19 10:35:36.563196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 10:35:36.563401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 10:35:36.563517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 10:35:36.952524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 10:35:36.952686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 10:35:36.952808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-19 10:35:36.952909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11054 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3786 - accuracy: 0.8971 - val_loss: 0.2065 - val_accuracy: 0.9423\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.9495 - val_loss: 0.1476 - val_accuracy: 0.9570\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1299 - accuracy: 0.9633 - val_loss: 0.1211 - val_accuracy: 0.9645\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9704 - val_loss: 0.1041 - val_accuracy: 0.9688\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0847 - accuracy: 0.9754 - val_loss: 0.0945 - val_accuracy: 0.9720\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9791 - val_loss: 0.0858 - val_accuracy: 0.9745\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0601 - accuracy: 0.9826 - val_loss: 0.0803 - val_accuracy: 0.9751\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0519 - accuracy: 0.9855 - val_loss: 0.0823 - val_accuracy: 0.9764\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0456 - accuracy: 0.9871 - val_loss: 0.0792 - val_accuracy: 0.9760\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0392 - accuracy: 0.9889 - val_loss: 0.0788 - val_accuracy: 0.9772\n",
      "CPU times: user 12.5 s, sys: 1.31 s, total: 13.8 s\n",
      "Wall time: 8.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0bf036c9d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(784,), activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# looking at the model summary\n",
    "model.summary()\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "%time model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07881936430931091, 0.9771999716758728]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 26, 26, 10)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6760)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               676100    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 677,210\n",
      "Trainable params: 677,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 10:35:46.506778: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20/469 [>.............................] - ETA: 1s - loss: 1.3218 - accuracy: 0.6879  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 10:35:46.841262: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2247 - accuracy: 0.9381 - val_loss: 0.0803 - val_accuracy: 0.9756\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0699 - accuracy: 0.9792 - val_loss: 0.0586 - val_accuracy: 0.9805\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0459 - accuracy: 0.9866 - val_loss: 0.0571 - val_accuracy: 0.9821\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0301 - accuracy: 0.9910 - val_loss: 0.0507 - val_accuracy: 0.9833\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.0519 - val_accuracy: 0.9840\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.0572 - val_accuracy: 0.9834\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0573 - val_accuracy: 0.9834\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0526 - val_accuracy: 0.9858\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0628 - val_accuracy: 0.9825\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0691 - val_accuracy: 0.9827\n",
      "CPU times: user 16.2 s, sys: 1.74 s, total: 18 s\n",
      "Wall time: 12.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0bf00b8640>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(10, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# looking at the model summary\n",
    "model.summary()\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "\n",
    "# training the model for 10 epochs\n",
    "%time model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0691300705075264, 0.982699990272522]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
